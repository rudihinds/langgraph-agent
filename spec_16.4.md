# Specification: Task 16.4 - Implement Connection Pairs Evaluation (`evaluateConnectionsNode`)

## 1. Overview

This document outlines the high-level specification for the `evaluateConnectionsNode` within the `ProposalGenerationGraph`. The primary goal of this node is to evaluate the quality and relevance of connection pairs generated by the `connectionPairsNode` and provide actionable feedback for improving these connections.

## 2. Node Purpose

To analyze `state.connections` against defined evaluation criteria to determine the overall quality of the identified connections between funder priorities and applicant capabilities. This includes:

- Assessing the relevance of connections to funder priorities
- Evaluating the specificity and detail level of connection descriptions
- Checking for supporting evidence within each connection
- Ensuring completeness of coverage across major funder priorities
- Measuring the strategic alignment quality beyond superficial matches
- Providing an overall pass/fail determination
- Generating actionable suggestions for improvement

The output should be a structured evaluation result that can be used to guide human reviewers in deciding whether to approve the connections or request revisions.

## 3. Integration Context

- **Graph:** Part of the `ProposalGenerationGraph`.
- **State:** Operates on the `OverallProposalState`.
- **Precedes:** Human review via HITL interruption.
- **Follows:** `connectionPairsNode`.
- **Triggers:** Human-in-the-Loop interruption for connection review.

## 4. Core Processing Logic

1.  **Input Validation:**
    - **Check:** `state.connections` exists and is non-empty.
    - **Check:** Connections are in the expected format (array of strings).
    - **Action on Fail:** Log error, update `state.connectionsStatus` to `error`, add details to `state.errors`, return state.
2.  **Status Update:** Set `state.connectionsStatus` = `'evaluating'`.
3.  **Agent Invocation:**
    - Create and invoke a specialized evaluation agent.
    - Provide connections, research results, and solution results as context for evaluation.
    - Set timeout prevention using Promise.race.
4.  **Response Processing:**
    - Receive the response, expected to be a **JSON string**.
    - **Parse:** Attempt `JSON.parse()` on the response content.
    - **Fallback:** If JSON parsing fails, attempt to extract evaluation data using regex.
    - **Action on Fail:** Log parsing/validation error, update `state.connectionsStatus` to `error`, add details to `state.errors`, return state.
5.  **Evaluation Result Validation:**
    - Check for required fields: score, passed, feedback, strengths, weaknesses, suggestions.
    - **Action on Fail:** Log validation error, update `state.connectionsStatus` to `error`, add details to `state.errors`, return state.
6.  **State Update (Success):**
    - Store the parsed evaluation in `state.connectionsEvaluation`.
    - Set `state.connectionsStatus` = `'awaiting_review'`.
    - Configure interrupt metadata with evaluation context for the UI.
    - Set interrupt status for HITL interruption.
    - Append relevant execution information to `state.messages`.
    - Clear any previous errors related to this node from `state.errors`.
7.  **Return:** Return the `Partial<OverallProposalState>` containing the updates.

## 5. Expected State Changes

- `state.connectionsEvaluation`: Populated with the evaluation results.
- `state.connectionsStatus`: Updated to `'evaluating'` during execution, then `'awaiting_review'` on success or `'error'` on failure.
- `state.interruptMetadata`: Set with evaluation context for the UI.
- `state.interruptStatus`: Set to trigger HITL interruption.
- `state.messages`: Appended with relevant logs/outputs.
- `state.errors`: Populated if errors occur during execution, cleared on success.
- `state.status`: Set to `'awaiting_review'` on success to indicate overall process status.

## 6. Error Handling Scenarios

The node must gracefully handle and report errors for:

- Missing or invalid input data (`connections`).
- Errors during agent invocation (API errors, timeouts, content filtering).
- Failure to parse the agent response as valid JSON (with fallback to regex extraction).
- Failure of the parsed response to include all required evaluation fields.
- Timeout situations with long-running agent operations.

In all error cases, `state.connectionsStatus` should be set to `'error'`, and a descriptive message added to `state.errors`.

## 7. Dependencies

- **Input Data:** Relies on successful completion and state update from `connectionPairsNode`.
- **Configuration:** Requires access to LLM client configuration and the evaluation agent prompt.
- **Output:** Provides the necessary `state.connectionsEvaluation` for HITL review and downstream decision-making.

## 8. Success Criteria (for Task 16.4 Implementation)

- The `evaluateConnectionsNode` implementation exists and is correctly integrated into the `ProposalGenerationGraph`.
- The node correctly validates its input state fields (`connections`).
- The node successfully creates and invokes the evaluation agent with proper context.
- The node correctly parses the expected JSON response from the agent.
- The node implements fallback regex extraction for non-JSON responses.
- Proper timeout prevention is implemented for long-running operations.
- Upon success, the node accurately updates `state.connectionsEvaluation`, `state.connectionsStatus` (to `awaiting_review`), and configures HITL interruption.
- The node handles all specified error scenarios gracefully, updating `state.connectionsStatus` (to `error`) and `state.errors`.
- Specific error handling exists for API errors, timeouts, and parsing failures.
- Comprehensive unit tests exist for the node, covering success paths, error handling, and various input scenarios.
- The node functions correctly within the overall application flow, pausing for human review at the appropriate point.

## 9. Evaluation Criteria Structure

The evaluation result should include:

```json
{
  "score": <number 1-10>,
  "passed": <boolean>,
  "feedback": "<overall assessment>",
  "strengths": ["<strength 1>", "<strength 2>", ...],
  "weaknesses": ["<weakness 1>", "<weakness 2>", ...],
  "suggestions": ["<suggestion 1>", "<suggestion 2>", ...]
}
```

Where:

- **score**: A numeric value from 1-10 where 10 is excellent
- **passed**: Boolean indicating whether the connections meet minimum quality standards (typically score â‰¥ 6)
- **feedback**: General assessment of the connection quality
- **strengths**: At least 2 specific strengths identified
- **weaknesses**: At least 1 specific area for improvement
- **suggestions**: At least 2 actionable suggestions for enhancing the connections

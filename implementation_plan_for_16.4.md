# Implementation Plan: Task 16.4 - Evaluate Connection Pairs (`evaluateConnectionsNode`)

## Overview

This document outlines the implementation plan for the `evaluateConnectionsNode` within the `ProposalGenerationGraph`. This node is responsible for evaluating the quality and relevance of the connection pairs generated by the previously implemented `connectionPairsNode` (Task 16.3).

## Related Files

- `spec_16.4.md` (if available)
- `apps/backend/agents/proposal-agent/nodes.ts` (contains example implementation)
- `apps/backend/agents/proposal-agent/__tests__/nodes.test.ts` (contains test cases)
- `apps/backend/agents/proposal-generation/conditionals.ts` (routing logic)
- `apps/backend/agents/proposal-generation/graph.ts` (graph integration)

## Implementation Tasks

### 1. Test Design Phase

1. **Review existing tests** to understand the expected behavior:

   - Test case for setting interrupt metadata and status correctly
   - Test case for handling missing connections

2. **Design additional test cases** to cover:
   - Input validation for various connection array formats
   - Evaluation agent invocation (mocked for tests)
   - Handling evaluation agent errors (timeout, rate limit, service errors)
   - Proper state updates for each scenario

### 2. Implementation Phase

1. **Node Function Implementation**:

   ```typescript
   /**
    * Node to evaluate the connection pairs between funder and applicant priorities
    * @param state Current proposal state
    * @returns Updated state with connection evaluation
    */
   export async function evaluateConnectionsNode(
     state: ProposalState
   ): Promise<Partial<ProposalState>> {
     // Input validation
     // Status update
     // Evaluation agent invocation
     // Process evaluation results
     // Set interrupt metadata and status for HITL
     // Return updated state
   }
   ```

2. **Input Validation**:

   - Check if `state.connections` exists and is non-empty
   - Verify connections have the expected format
   - Handle error cases with appropriate state updates

3. **Evaluation Agent Implementation**:

   - Create an agent that evaluates connection pairs quality
   - Define criteria for evaluation (relevance, specificity, strength)
   - Generate detailed feedback with strengths, weaknesses, and suggestions
   - Determine an overall pass/fail status based on evaluation

4. **Response Processing**:

   - Parse and validate the agent's evaluation response
   - Create a standardized evaluation result structure
   - Include pass/fail status, overall score, feedback, strengths, weaknesses, and suggestions

5. **Error Handling**:

   - Handle agent invocation errors (timeouts, rate limits, etc.)
   - Implement fallback mechanisms for partial results
   - Ensure consistent error messaging patterns

6. **State Updates**:
   - Store evaluation results in `state.connectionsEvaluation`
   - Set `state.connectionsStatus` appropriately
   - Configure interrupt metadata for HITL review
   - Update `state.messages` with execution logs

### 3. Test Verification Phase

1. Run tests to verify:

   - Input validation works correctly
   - Agent is invoked with proper parameters
   - Response processing correctly extracts and validates evaluation results
   - State is updated correctly for both success and error cases
   - Interrupt metadata is set properly for HITL review

2. Complete test coverage to ensure all edge cases are handled.

### 4. Integration Phase

1. Integrate the node into the main graph:

   ```typescript
   // In apps/backend/agents/proposal-generation/graph.ts

   // Add the node to the graph
   graph.addNode("evaluateConnections", evaluateConnectionsNode);

   // Connect it with edges
   graph.addEdge("connectionPairs", "evaluateConnections");

   // Set up conditional routing based on evaluation
   graph.addConditionalEdges(
     "evaluateConnections",
     routeAfterConnectionsEvaluation,
     {
       sections: "sectionManager",
       revise: "connectionPairs",
     }
   );
   ```

2. Configure HITL interruption point:
   ```typescript
   // HITL Configuration
   graph.compiler.interruptAfter([
     "evaluateConnectionsNode",
     // ...other evaluation nodes
   ]);
   ```

## Technical Implementation Notes

1. **Evaluation Criteria Structure**: The evaluation should assess:

   - Relevance: How well the connections align with funder priorities
   - Specificity: How detailed and concrete the connections are
   - Evidence: Whether connections are supported by specific examples
   - Completeness: Whether all major funder priorities are addressed
   - Strategic Alignment: Whether connections show meaningful strategic fit

2. **Human-in-the-Loop Flow**: This node must pause execution for human review, allowing the user to:

   - Approve the evaluation and continue to section generation
   - Request revisions to the connection pairs
   - Configure what specific aspects need improvement

3. **Error Classification**: Follow the established pattern of classifying errors by type:

   - Timeout errors
   - Rate limit errors
   - Service errors
   - Validation errors

4. **State Management**: Ensure proper state transitions:

   - Start: `state.connectionsStatus = 'completed'` (from connectionPairsNode)
   - During: `state.connectionsStatus = 'evaluating'`
   - End (Success): `state.connectionsStatus = 'awaiting_review'`
   - End (Failure): `state.connectionsStatus = 'error'`

5. **HITL Context**: Provide rich context for the human reviewer:
   - Overall evaluation score and pass/fail status
   - Specific strengths identified in the connections
   - Areas of weakness that could be improved
   - Concrete suggestions for enhancement

## Testing Strategy

Following Test-Driven Development (TDD) principles:

1. **Red Phase**: First, run the tests expecting them to fail
2. **Green Phase**: Implement the minimal code needed to pass the tests
3. **Refactor Phase**: Improve the code while maintaining passing tests

**Test Coverage Areas**:

- Input validation (missing connections, empty array, malformed data)
- Agent invocation (proper prompt construction, error handling)
- Response processing (valid evaluations, edge cases)
- State management (proper state updates in all scenarios)
- Error handling (timeouts, rate limits, service errors, validation errors)
- HITL context (interrupt metadata properly formatted for UI)

## Next Steps

Once the `evaluateConnectionsNode` is implemented and tested:

1. Begin work on section generation nodes (if not already completed)
2. Ensure proper integration with the section manager node
3. Update documentation to reflect the new node and its role in the workflow
